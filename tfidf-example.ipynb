{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "[nltk_data] Downloading package stopwords to /home/nvidia/nltk_data...\n[nltk_data]   Package stopwords is already up-to-date!\n"
    }
   ],
   "source": [
    "import gensim\n",
    "import nltk\n",
    "import numpy as np\n",
    "import re\n",
    "import pandas as pd\n",
    "nltk.download('stopwords')\n",
    "\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize, RegexpTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "from gensim.summarization.summarizer import summarize\n",
    "from gensim.summarization import keywords\n",
    "from docx import Document\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _removeNonAscii(s):\n",
    "    return \"\".join(i for i in s if  ord(i)<128)\n",
    "\n",
    "def make_lower_case(text):\n",
    "    return text.lower()\n",
    "\n",
    "def remove_stop_words(text):\n",
    "    text = text.split()\n",
    "    stops = set(stopwords.words(\"english\"))\n",
    "    text = [w for w in text if not w in stops]\n",
    "    text = \" \".join(text)\n",
    "    return text\n",
    "\n",
    "def remove_html(text):\n",
    "    html_pattern = re.compile('<.*?>')\n",
    "    return html_pattern.sub(r'', text)\n",
    "\n",
    "def remove_punctuation(text):\n",
    "    tokenizer = RegexpTokenizer(r'\\w+')\n",
    "    text = tokenizer.tokenize(text)\n",
    "    text = \" \".join(text)\n",
    "    return text\n",
    "\n",
    "def clean_text(text):\n",
    "    return_text = _removeNonAscii(text)\n",
    "    return_text = make_lower_case(return_text)\n",
    "    return_text = remove_stop_words(return_text)\n",
    "    return_text = remove_html(return_text)\n",
    "    return_text = remove_punctuation(return_text)\n",
    "    return return_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "'I want to work for <company> because I believe that your company is the perfect intersection between my passion for innovative media and brand communication as well as my skills gained from diverse copywriting experiences.\\nAs the Event Planning Intern at the Greenwich Village Chelsea Chamber of Commerce (GVCCC), I gained significant experience in copywriting for event marketing materials.\\nIn this position, I drafted and edited several rounds of event copy, online event registration pages, and email invitations to ensure brand consistency through writing style, tone, and voice.\\nThis experience taught me about the importance of achieving a solid understanding of each organization’s goals to create a marketing message built on a strong synthesis of all brands.\\nI believe that this skill will transfer to this position because of Moss Adams’s diverse set of relationships and messaging when working with various clients.\\nSince we regularly work on more than one event at a time, I possess the ability to effective prioritize assignments and competing deadlines.\\nMy responsibilities include leading PR Team meetings, managing brand presence on Facebook and Instagram, as well as writing and editing copy for twice weekly social media posts.\\nI believe that working in a position such as this will surely deepen and enrich my professional goals in copywriting.'"
     },
     "metadata": {},
     "execution_count": 30
    }
   ],
   "source": [
    "filename = './input/cover_letter.docx'\n",
    "doc = Document(filename)\n",
    "full_cover_letter = \"\"\n",
    "for p in doc.paragraphs:\n",
    "    full_cover_letter += p.text\n",
    "\n",
    "text_resume = str(full_cover_letter) # Summarize the text with ratio 0.1 (10% of the total words.)\n",
    "summarize(text_resume, ratio=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "'Ideal candidate has a background in the humanities, attention to detail, and a desire to earn experience in the book publishing industry.\\n• BA or BS, preferably in English or journalism (minor or area of concentration in history, religion, philosophy, political science, or any other discipline in which RLPG publishes).\\n• Knowledge of MS Office suite (Word, Excel, Access) and Windows\\n• Excellent communication and time-management skills'"
     },
     "metadata": {},
     "execution_count": 33
    }
   ],
   "source": [
    "job_desc = \"\"\"Rowman & Littlefield is seeking an entry-level Editorial Assistant for its Lanham, Maryland, office. The Editorial Assistant will support senior editors in its busy editorial production department, assisting with many aspects of production of academic and trade titles, as well as some administrative functions. Ideal candidate has a background in the humanities, attention to detail, and a desire to earn experience in the book publishing industry.\n",
    "\n",
    "Requirements\n",
    "• BA or BS, preferably in English or journalism (minor or area of concentration in history, religion, philosophy, political science, or any other discipline in which RLPG publishes).\n",
    "• Knowledge of the Chicago Manual of Style (familiarity with APA and other style guides a bonus)\n",
    "• Knowledge of MS Office suite (Word, Excel, Access) and Windows\n",
    "• Excellent communication and time-management skills\"\"\"\n",
    "\n",
    "summarize(job_desc, ratio=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def similarity(document_array, query_array):\n",
    "    file_docs = document_array\n",
    "    file2_docs = query_array\n",
    "    avg_sims = []\n",
    "    \n",
    "    gen_docs = [[w.lower() for w in word_tokenize(text)] \n",
    "                for text in file_docs]\n",
    "\n",
    "    dictionary = gensim.corpora.Dictionary(gen_docs)\n",
    "    corpus = [dictionary.doc2bow(gen_doc) for gen_doc in gen_docs]\n",
    "    tf_idf = gensim.models.TfidfModel(corpus)\n",
    "    sims = gensim.similarities.Similarity('sim_checkpoints/',tf_idf[corpus],\n",
    "                                        num_features=len(dictionary))\n",
    "            \n",
    "    for line in file2_docs:\n",
    "        query_doc = [w.lower() for w in word_tokenize(line)]\n",
    "        query_doc_bow = dictionary.doc2bow(query_doc)\n",
    "        query_doc_tf_idf = tf_idf[query_doc_bow]\n",
    "        print('Comparing Result for {}: {}'.format(line, sims[query_doc_tf_idf]))\n",
    "        sum_of_sims =(np.sum(sims[query_doc_tf_idf], dtype=np.float32))\n",
    "        avg = sum_of_sims / len(file_docs)\n",
    "        print(f'avg: {sum_of_sims / len(file_docs)}')\n",
    "        avg_sims.append(avg)  \n",
    "    total_avg = np.sum(avg_sims, dtype=np.float)\n",
    "    print(total_avg)\n",
    "    percentage_of_similarity = round(float(total_avg) * 100)\n",
    "    if percentage_of_similarity >= 100:\n",
    "        percentage_of_similarity = 100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Comparing Result for cassandra chia: [0. 0. 0. 0. 0.]\navg: 0.0\nComparing Result for : [0. 0. 0. 0. 0.]\navg: 0.0\nComparing Result for 728 bowery st iowa city ia 52240 202 718 8644: [0. 0. 0. 0. 0.]\navg: 0.0\nComparing Result for cassqchia gmail com: [0. 0. 0. 0. 0.]\navg: 0.0\nComparing Result for 19 october 2020: [0. 0. 0. 0. 0.]\navg: 0.0\nComparing Result for : [0. 0. 0. 0. 0.]\navg: 0.0\nComparing Result for moss adams: [0. 0. 0. 0. 0.]\navg: 0.0\nComparing Result for 999 third avenue suite 2800: [0.         0.         0.         0.         0.19871596]\navg: 0.03974319100379944\nComparing Result for seattle wa 98104 4057: [0. 0. 0. 0. 0.]\navg: 0.0\nComparing Result for : [0. 0. 0. 0. 0.]\navg: 0.0\nComparing Result for dear hiring manager: [0. 0. 0. 0. 0.]\navg: 0.0\nComparing Result for writing express interest position currently completing last semester university iowa english creative writing major literary publishing track graduation date december 2020 available work january 4 2021 want work believe company perfect intersection passion innovative media brand communication well skills gained diverse copywriting experiences: [0.         0.10096209 0.12909944 0.10846522 0.17773695]\navg: 0.10325274467468262\nComparing Result for event planning intern greenwich village chelsea chamber commerce gvccc gained significant experience copywriting event marketing materials position drafted edited several rounds event copy online event registration pages email invitations ensure brand consistency writing style tone voice collaborated different nyc businessesfrom working law firm organize five day webinar series business reopening working new school organize moderated discussion centered race business experience taught importance achieving solid understanding organizations goals create marketing message built strong synthesis brands believe skill transfer position moss adamss diverse set relationships messaging working various clients additionally strong attention detail successfully planned 15 virtual events coordinating detailsfrom pitching events scheduling events securing sponsors since regularly work one event time possess ability effective prioritize assignments competing deadlines turn confident transfer skills knowledge team especially comes driving marketing sales initiatives: [0.         0.         0.36514837 0.         0.377037  ]\navg: 0.1484370708465576\nComparing Result for beyond experience related events copywriting experience social media web content well editorial experience currently serve public relations director earthwords undergraduate literary review responsibilities include leading pr team meetings managing brand presence facebook instagram well writing editing copy twice weekly social media posts significant undertaking time earthwords complete rebuilding website ground up project taught use wordpress edited blog content challenge required to among things conduct market research brainstorm new media angles successful engagement regularly analyzing social media statistics nonfiction intern iowa review strong command english language time evaluating 600 submissions writing readers reports proofreading galleys according chicago manual style also possess excellent verbal written communication skills working together team equipped ability juggle multiple projects once collaborate others well work independently strong editorial sensibilities prove great fit company prioritizes high standard writing: [0.04171167 0.17622338 0.15733825 0.04406352 0.32492185]\navg: 0.14885172843933106\nComparing Result for believe working position surely deepen enrich professional goals copywriting that however pursuing opportunity believe invests clientss needs prosperity hence thrilled opportunity able contribute skills passion experiences background given unique perspective intricacies copywriting therefore making competitive candidate job welcome opportunity discuss position detail thank time consideration look forward response: [0.         0.         0.38729835 0.         0.17773695]\navg: 0.11300705671310425\nComparing Result for sincerely: [0. 0. 0. 0. 0.]\navg: 0.0\nComparing Result for cassandra chia: [0. 0. 0. 0. 0.]\navg: 0.0\nComparing Result for : [0. 0. 0. 0. 0.]\navg: 0.0\n0.553291791677475\n"
    }
   ],
   "source": [
    "job_desc_cleaned = [clean_text(sentence) for sentence in job_desc.split('.')]\n",
    "clean_cover_letter = [clean_text(sentence.text) for sentence in doc.paragraphs]\n",
    "similarity(job_desc_cleaned, clean_cover_letter)\n",
    "# print(job_desc_cleaned)\n",
    "# clean_cover_letter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array([[1.        , 0.17668795, 0.27056873, 0.        , 0.        ],\n       [0.17668795, 1.        , 0.15439436, 0.        , 0.        ],\n       [0.27056873, 0.15439436, 1.        , 0.19635649, 0.16815247],\n       [0.        , 0.        , 0.19635649, 1.        , 0.54499756],\n       [0.        , 0.        , 0.16815247, 0.54499756, 1.        ]])"
     },
     "metadata": {},
     "execution_count": 68
    }
   ],
   "source": [
    "corpus = [\"I'd like an apple\", \"An apple a day keeps the doctor away\", \"Never compare an apple to an orange\", \"I prefer scikit-learn to Orange\", \"The scikit-learn docs are Orange and Blue\"]\n",
    "# corpus = clean_cover_letter\n",
    "# corpus.append(clean_text(job_desc))\n",
    "vect = TfidfVectorizer(min_df=1, stop_words=\"english\")                        \n",
    "tfidf = vect.fit_transform(corpus)                                                                      \n",
    "pairwise_similarity = tfidf * tfidf.T \n",
    "pairwise_similarity.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "4\nI prefer scikit-learn to Orange\n[0.         0.         0.16815247 0.54499756        nan]\n"
    }
   ],
   "source": [
    "arr = pairwise_similarity.toarray() \n",
    "np.fill_diagonal(arr, np.nan)\n",
    "input_doc = corpus[-1]\n",
    "input_idx = corpus.index(input_doc)\n",
    "print(input_idx)\n",
    "\n",
    "result_idx = np.nanargmax(arr[input_idx]) \n",
    "print(corpus[result_idx])\n",
    "print(arr[input_idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filename = './input/resume_002.docx'\n",
    "# doc = Document(filename)\n",
    "# full_cover_letter = \"\"\n",
    "# for p in doc.paragraphs:\n",
    "#     full_cover_letter += p.text\n",
    "\n",
    "# for table in doc.tables:\n",
    "#     for row in table.rows:\n",
    "#         for cell in row.cells:\n",
    "#             full_cover_letter += cell.text\n",
    "\n",
    "# text_resume = str(full_cover_letter) # Summarize the text with ratio 0.1 (10% of the total words.)\n",
    "# summarize(text_resume, ratio=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Job title: Software Engineer - 09/2015 to 05/2019\nCompany: Luna Software, New York\nInvestigation, design, and implement scalable applications for data identification, analysis, retrieval, and indexing.\nSoftware design and development while remaining concentrate on client needs.\nCooperate diligently with other IT team members to plan, design, and develop smart solutions.\nEstimate interface between hardware and software.\nInterface with business analysts, developers, and technical support to determine optimal specifications.\n\nJob title: Junior Software Engineer - 09/2014 to 09/2015\nCompany: AdsPro Software, New York\nConsulted regularly with customers on project status, proposals and technical issues.\nTransformed existing software to correct errors, upgrade interfaces, and improve efficiency.\nCooperate diligently with other IT team members to plan, design, and develop smart solutions.\n"
    }
   ],
   "source": [
    "f = open(\"./input/resume.txt\", \"r\")\n",
    "exp_array = []\n",
    "job_id_array = []\n",
    "job_id = 0 \n",
    "for x in f:\n",
    "  if ('<sep>' in x): \n",
    "      print(\"\")\n",
    "      job_id += 1\n",
    "  elif ('<job>' in x): print(\"Job title: {}\".format(x.strip().replace('<job>','')))\n",
    "  elif ('<com>' in x): print(\"Company: {}\".format(x.strip().replace('<com>','')))\n",
    "  else: \n",
    "      print(x.strip())\n",
    "      exp_array.append(clean_text(x.strip()))\n",
    "      job_id_array.append(job_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "f = open(\"./input/job_desc.txt\", \"r\")\n",
    "job_desc_string = \"\"\n",
    "for x in f:\n",
    "    job_desc_string += x.strip()\n",
    "\n",
    "job_desc_string = clean_text(job_desc_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array([[1.        , 0.04842342, 0.04820191, 0.        , 0.        ,\n        0.        , 0.        , 0.04820191, 0.05942944],\n       [0.04842342, 1.        , 0.06100803, 0.10168122, 0.        ,\n        0.        , 0.06203475, 0.06100803, 0.12702242],\n       [0.04820191, 0.06100803, 1.        , 0.        , 0.        ,\n        0.        , 0.        , 1.        , 0.07524141],\n       [0.        , 0.10168122, 0.        , 1.        , 0.14276461,\n        0.        , 0.08194772, 0.        , 0.04807007],\n       [0.        , 0.        , 0.        , 0.14276461, 1.        ,\n        0.06958921, 0.        , 0.        , 0.02242913],\n       [0.        , 0.        , 0.        , 0.        , 0.06958921,\n        1.        , 0.        , 0.        , 0.00992565],\n       [0.        , 0.06203475, 0.        , 0.08194772, 0.        ,\n        0.        , 1.        , 0.        , 0.0293271 ],\n       [0.04820191, 0.06100803, 1.        , 0.        , 0.        ,\n        0.        , 0.        , 1.        , 0.07524141],\n       [0.05942944, 0.12702242, 0.07524141, 0.04807007, 0.02242913,\n        0.00992565, 0.0293271 , 0.07524141, 1.        ]])"
     },
     "metadata": {},
     "execution_count": 84
    }
   ],
   "source": [
    "corpus = exp_array\n",
    "corpus.append(job_desc_string)\n",
    "\n",
    "vect = TfidfVectorizer(min_df=1, stop_words=\"english\")\n",
    "tfidf = vect.fit_transform(corpus)\n",
    "pairwise_similarity = tfidf * tfidf.T \n",
    "pairwise_similarity.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "8\nsoftware design development remaining concentrate client needs\n[0.05942944 0.12702242 0.07524141 0.04807007 0.02242913 0.00992565\n 0.0293271  0.07524141        nan]\n"
    }
   ],
   "source": [
    "arr = pairwise_similarity.toarray() \n",
    "np.fill_diagonal(arr, np.nan)\n",
    "input_doc = corpus[-1]\n",
    "input_idx = corpus.index(input_doc)\n",
    "print(input_idx)\n",
    "\n",
    "result_idx = np.nanargmax(arr[input_idx]) \n",
    "print(corpus[result_idx])\n",
    "print(arr[input_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array([0.05942944, 0.12702242, 0.07524141, 0.04807007, 0.02242913,\n       0.00992565, 0.0293271 , 0.07524141])"
     },
     "metadata": {},
     "execution_count": 86
    }
   ],
   "source": [
    "arr[input_idx][0:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {'exp': exp_array[0:-1], 'job_id': job_id_array, 'sim': arr[input_idx][0:-1]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "                                                 exp  job_id       sim\n0  investigation design implement scalable applic...       0  0.059429\n1  software design development remaining concentr...       0  0.127022\n2  cooperate diligently team members plan design ...       0  0.075241\n3               estimate interface hardware software       0  0.048070\n4  interface business analysts developers technic...       0  0.022429",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>exp</th>\n      <th>job_id</th>\n      <th>sim</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>investigation design implement scalable applic...</td>\n      <td>0</td>\n      <td>0.059429</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>software design development remaining concentr...</td>\n      <td>0</td>\n      <td>0.127022</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>cooperate diligently team members plan design ...</td>\n      <td>0</td>\n      <td>0.075241</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>estimate interface hardware software</td>\n      <td>0</td>\n      <td>0.048070</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>interface business analysts developers technic...</td>\n      <td>0</td>\n      <td>0.022429</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 95
    }
   ],
   "source": [
    "df = pd.DataFrame(data) \n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "                                                 exp  job_id       sim\n7  cooperate diligently team members plan design ...       1  0.075241\n6  transformed existing software correct errors u...       1  0.029327\n5  consulted regularly customers project status p...       1  0.009926\n1  software design development remaining concentr...       0  0.127022\n2  cooperate diligently team members plan design ...       0  0.075241\n0  investigation design implement scalable applic...       0  0.059429\n3               estimate interface hardware software       0  0.048070\n4  interface business analysts developers technic...       0  0.022429",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>exp</th>\n      <th>job_id</th>\n      <th>sim</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>7</th>\n      <td>cooperate diligently team members plan design ...</td>\n      <td>1</td>\n      <td>0.075241</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>transformed existing software correct errors u...</td>\n      <td>1</td>\n      <td>0.029327</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>consulted regularly customers project status p...</td>\n      <td>1</td>\n      <td>0.009926</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>software design development remaining concentr...</td>\n      <td>0</td>\n      <td>0.127022</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>cooperate diligently team members plan design ...</td>\n      <td>0</td>\n      <td>0.075241</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>investigation design implement scalable applic...</td>\n      <td>0</td>\n      <td>0.059429</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>estimate interface hardware software</td>\n      <td>0</td>\n      <td>0.048070</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>interface business analysts developers technic...</td>\n      <td>0</td>\n      <td>0.022429</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 97
    }
   ],
   "source": [
    "df.sort_values(by=['job_id', 'sim'], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: write the new order to file\n",
    "# TODO: allow users to use <ignore> tag for sentences that are more explanatory for whole job\n",
    "# TODO: question if this is really getting to the heart of the problem. Simple ML may not be able to tackle the harder issue of ensuring this is all correct. Maybe instead, if we have 3 different resumes, we are to categorize them according to job description and somehow decide which ones to send off? Either way, a simple prototype like this may not be the best method of going forward for now."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.6 64-bit ('base': conda)",
   "language": "python",
   "name": "python37664bitbaseconda66ad337704e04e7290b604b07f248736"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}